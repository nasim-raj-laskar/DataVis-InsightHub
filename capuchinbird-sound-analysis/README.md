# Capuchinbird-sound-analysis ğŸ¦

## ğŸ¯ Project Overview
CapuchinNet is an audio-based machine learning project focused on detecting Capuchinbird calls amidst diverse environmental noise. Utilizing spectrogram analysis, YAMNet embeddings, and transfer learning, this project builds an effective classification model to distinguish Capuchinbird calls from other noises.

## ğŸš€ Features
- #### ğŸµ Preprocessing Methods:
  - White Noise Addition
  - Volume Normalization
  - High/Low-Frequency Filtering
- #### ğŸ“Š Audio Transformation:
  - Waveform to Spectrogram Conversion
  - STFT Spectrogram Analysis
  - Visualization of Spectrograms and Predictions
- #### ğŸ§  Machine Learning Models:
  - CNN Model: Trained from scratch to classify audio spectrograms.
  - YAMNet-based Transfer Learning: Leverages Googleâ€™s YAMNet embeddings for efficient audio classification.
- #### ğŸ“ˆ Model Evaluation:
  - Performance visualization with loss & accuracy plots.
  - Confusion Matrix Analysis.

## ğŸ“Š Results
- Test Accuracy: X%
- Number of Correctly Detected Calls: Y / Z
## ğŸ› ï¸ Technologies Used
- Python
- TensorFlow & Keras
- YAMNet
- pydub
- Seaborn & Matplotlib
